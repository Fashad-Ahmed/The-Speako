{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zenML_Pipeline_Transcription.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fashad-Ahmed/The-Speako/blob/trancription-branch-tash-v1/zenML_Pipeline_Transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FjIICrmSd8ZH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "547fbc4d-ebd8-4bca-cf2e-51a71c4cd880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting zenML\n",
            "  Downloading zenml-0.11.0-py3-none-any.whl (795 kB)\n",
            "\u001b[K     |████████████████████████████████| 795 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.8.1 in /usr/local/lib/python3.7/dist-packages (from zenML) (2.8.2)\n",
            "Collecting gitpython<4.0.0,>=3.1.18\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 42.6 MB/s \n",
            "\u001b[?25hCollecting pyparsing<3,>=2.4.0\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting ml-pipelines-sdk==1.8.0\n",
            "  Downloading ml_pipelines_sdk-1.8.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 51.3 MB/s \n",
            "\u001b[?25hCollecting distro<2.0.0,>=1.6.0\n",
            "  Downloading distro-1.7.0-py3-none-any.whl (20 kB)\n",
            "Collecting httplib2<0.20,>=0.19.1\n",
            "  Downloading httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
            "\u001b[K     |████████████████████████████████| 95 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<2.0.0,>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from zenML) (1.3.5)\n",
            "Collecting analytics-python<2.0.0,>=1.4.0\n",
            "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting click<9.0.0,>=8.0.1\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting apache-beam<3.0.0,>=2.30.0\n",
            "  Downloading apache_beam-2.40.0-cp37-cp37m-manylinux2010_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 40.1 MB/s \n",
            "\u001b[?25hCollecting sqlmodel<0.1.0,>=0.0.6\n",
            "  Downloading sqlmodel-0.0.6-py3-none-any.whl (21 kB)\n",
            "Collecting pyyaml<6.0.0,>=5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 43.8 MB/s \n",
            "\u001b[?25hCollecting rich[jupyter]<13.0.0,>=12.0.0\n",
            "  Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 38.1 MB/s \n",
            "\u001b[?25hCollecting markupsafe==1.1.1\n",
            "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
            "Collecting pydantic<2.0.0,>=1.9.0\n",
            "  Downloading pydantic-1.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 39.6 MB/s \n",
            "\u001b[?25hCollecting nbconvert==6.4.4\n",
            "  Downloading nbconvert-6.4.4-py3-none-any.whl (561 kB)\n",
            "\u001b[K     |████████████████████████████████| 561 kB 56.4 MB/s \n",
            "\u001b[?25hCollecting click-params<0.4.0,>=0.3.0\n",
            "  Downloading click_params-0.3.0-py3-none-any.whl (12 kB)\n",
            "Collecting packaging<21,>=20\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting ml-metadata<1.9.0,>=1.8.0\n",
            "  Downloading ml_metadata-1.8.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 45.1 MB/s \n",
            "\u001b[?25hCollecting docker<5,>=4.1\n",
            "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 52.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.7/dist-packages (from ml-pipelines-sdk==1.8.0->zenML) (1.2.0)\n",
            "Requirement already satisfied: portpicker<2,>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from ml-pipelines-sdk==1.8.0->zenML) (1.3.9)\n",
            "Requirement already satisfied: protobuf<4,>=3.13 in /usr/local/lib/python3.7/dist-packages (from ml-pipelines-sdk==1.8.0->zenML) (3.17.3)\n",
            "Requirement already satisfied: google-api-python-client<2,>=1.8 in /usr/local/lib/python3.7/dist-packages (from ml-pipelines-sdk==1.8.0->zenML) (1.12.11)\n",
            "Collecting google-apitools<1,>=0.5\n",
            "  Downloading google_apitools-0.5.32-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 60.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2<4,>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from ml-pipelines-sdk==1.8.0->zenML) (2.11.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert==6.4.4->zenML) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert==6.4.4->zenML) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert==6.4.4->zenML) (1.5.0)\n",
            "Collecting nbclient<0.6.0,>=0.5.0\n",
            "  Downloading nbclient-0.5.13-py3-none-any.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert==6.4.4->zenML) (0.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert==6.4.4->zenML) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert==6.4.4->zenML) (5.0.1)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert==6.4.4->zenML) (5.4.0)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert==6.4.4->zenML) (2.6.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert==6.4.4->zenML) (4.11.1)\n",
            "Requirement already satisfied: traitlets>=5.0 in /usr/local/lib/python3.7/dist-packages (from nbconvert==6.4.4->zenML) (5.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from nbconvert==6.4.4->zenML) (4.6.3)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert==6.4.4->zenML) (0.2.2)\n",
            "Collecting backoff==1.10.0\n",
            "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python<2.0.0,>=1.4.0->zenML) (1.15.0)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in /usr/local/lib/python3.7/dist-packages (from analytics-python<2.0.0,>=1.4.0->zenML) (2.23.0)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 62.6 MB/s \n",
            "\u001b[?25hCollecting requests<3.0,>=2.7\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting cloudpickle<3,>=2.1.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenML) (2022.1)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenML) (1.7)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.5.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 40.5 MB/s \n",
            "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.20.6-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 45.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenML) (4.1.1)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenML) (1.21.6)\n",
            "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenML) (6.0.1)\n",
            "Requirement already satisfied: grpcio<2,>=1.33.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenML) (1.47.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.7.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 58.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenML) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click<9.0.0,>=8.0.1->zenML) (4.12.0)\n",
            "Collecting validators<0.19,>=0.18\n",
            "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenML) (0.0.4)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenML) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenML) (1.31.6)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenML) (3.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenML) (1.56.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenML) (57.4.0)\n",
            "Collecting fasteners>=0.14\n",
            "  Downloading fasteners-0.17.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: oauth2client>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from google-apitools<1,>=0.5->ml-pipelines-sdk==1.8.0->zenML) (4.1.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenML) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenML) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk==1.8.0->zenML) (4.8)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam<3.0.0,>=2.30.0->zenML) (0.6.2)\n",
            "Collecting attrs<21,>=20.3\n",
            "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting jupyter-client>=6.1.5\n",
            "  Downloading jupyter_client-7.3.4-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 60.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert==6.4.4->zenML) (1.5.5)\n",
            "Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert==6.4.4->zenML) (23.2.0)\n",
            "Collecting tornado>=6.0\n",
            "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
            "\u001b[K     |████████████████████████████████| 423 kB 51.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert==6.4.4->zenML) (2.16.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert==6.4.4->zenML) (4.3.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert==6.4.4->zenML) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert==6.4.4->zenML) (5.8.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.4->nbconvert==6.4.4->zenML) (3.8.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=1.4.12->google-apitools<1,>=0.5->ml-pipelines-sdk==1.8.0->zenML) (0.4.8)\n",
            "Collecting protobuf<4,>=3.13\n",
            "  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenML) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenML) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenML) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenML) (1.24.3)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets<8.0.0,>=7.5.1 in /usr/local/lib/python3.7/dist-packages (from rich[jupyter]<13.0.0,>=12.0.0->zenML) (7.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenML) (3.6.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenML) (0.2.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenML) (5.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenML) (4.10.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenML) (1.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenML) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenML) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenML) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenML) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenML) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenML) (0.2.5)\n",
            "Collecting sqlalchemy2-stubs\n",
            "  Downloading sqlalchemy2_stubs-0.0.2a24-py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy<1.5.0,>=1.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlmodel<0.1.0,>=0.0.6->zenML) (1.4.39)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy<1.5.0,>=1.4.17->sqlmodel<0.1.0,>=0.0.6->zenML) (1.1.2)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenML) (5.3.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenML) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenML) (0.13.3)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]<13.0.0,>=12.0.0->zenML) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert==6.4.4->zenML) (0.5.1)\n",
            "Building wheels for collected packages: dill\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=c3f3ed371d98e6365c6c7a480f1df00ead806a1dd3647a8b83855ee85143d963\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "Successfully built dill\n",
            "Installing collected packages: attrs, tornado, markupsafe, jupyter-client, nbclient, pyparsing, protobuf, nbconvert, requests, packaging, httplib2, websocket-client, smmap, fasteners, commonmark, validators, sqlalchemy2-stubs, rich, pymongo, pydantic, proto-plus, orjson, monotonic, ml-metadata, hdfs, google-apitools, gitdb, fastavro, docker, dill, cloudpickle, click, backoff, sqlmodel, pyyaml, ml-pipelines-sdk, gitpython, distro, click-params, apache-beam, analytics-python, zenML\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.4.0\n",
            "    Uninstalling attrs-21.4.0:\n",
            "      Successfully uninstalled attrs-21.4.0\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 5.3.5\n",
            "    Uninstalling jupyter-client-5.3.5:\n",
            "      Successfully uninstalled jupyter-client-5.3.5\n",
            "  Attempting uninstall: nbclient\n",
            "    Found existing installation: nbclient 0.6.6\n",
            "    Uninstalling nbclient-0.6.6:\n",
            "      Successfully uninstalled nbclient-0.6.6\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: nbconvert\n",
            "    Found existing installation: nbconvert 5.6.1\n",
            "    Uninstalling nbconvert-5.6.1:\n",
            "      Successfully uninstalled nbconvert-5.6.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "  Attempting uninstall: httplib2\n",
            "    Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.1.1\n",
            "    Uninstalling pymongo-4.1.1:\n",
            "      Successfully uninstalled pymongo-4.1.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.8.2\n",
            "    Uninstalling pydantic-1.8.2:\n",
            "      Successfully uninstalled pydantic-1.8.2\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.0.17 requires pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4, but you have pydantic 1.9.1 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "spacy 3.3.1 requires pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4, but you have pydantic 1.9.1 which is incompatible.\n",
            "multiprocess 0.70.13 requires dill>=0.3.5.1, but you have dill 0.3.1.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.2 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed analytics-python-1.4.0 apache-beam-2.40.0 attrs-20.3.0 backoff-1.10.0 click-8.1.3 click-params-0.3.0 cloudpickle-2.1.0 commonmark-0.9.1 dill-0.3.1.1 distro-1.7.0 docker-4.4.4 fastavro-1.5.3 fasteners-0.17.3 gitdb-4.0.9 gitpython-3.1.27 google-apitools-0.5.32 hdfs-2.7.0 httplib2-0.19.1 jupyter-client-7.3.4 markupsafe-1.1.1 ml-metadata-1.8.0 ml-pipelines-sdk-1.8.0 monotonic-1.6 nbclient-0.5.13 nbconvert-6.4.4 orjson-3.7.8 packaging-20.9 proto-plus-1.20.6 protobuf-3.20.1 pydantic-1.9.1 pymongo-3.12.3 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.1 rich-12.5.1 smmap-5.0.0 sqlalchemy2-stubs-0.0.2a24 sqlmodel-0.0.6 tornado-6.2 validators-0.18.2 websocket-client-1.3.3 zenML-0.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "pyparsing",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install zenML"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zenml init"
      ],
      "metadata": {
        "id": "p6XoR5hGmaXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a678f77-2c7e-4965-dcf3-5ac135835ebf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "\u001b[?25l\u001b[1;35mInitializing the ZenML global configuration version to 0.11.0\u001b[0m\n",
            "\u001b[1;35mCreating default profile...\u001b[0m\n",
            "\u001b[1;35mInitializing profile \u001b[0m\u001b[33mdefault\u001b[1;35m...\u001b[0m\n",
            "\u001b[1;35mRegistering default stack...\u001b[0m\n",
            "\u001b[32m⠋\u001b[0m Initializing ZenML repository at /content.\n",
            "\u001b[1;35mRegistered stack component with type 'orchestrator' and name 'default'.\u001b[0m\n",
            "\u001b[1;35mRegistered stack component with type 'metadata_store' and name 'default'.\u001b[0m\n",
            "\u001b[1;35mRegistered stack component with type 'artifact_store' and name 'default'.\u001b[0m\n",
            "\u001b[1;35mRegistered stack with name 'default'.\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠙\u001b[0m Initializing ZenML repository at /content.\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠹\u001b[0m Initializing ZenML repository at /content.\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠸\u001b[0m Initializing ZenML repository at /content.\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠼\u001b[0m Initializing ZenML repository at /content.\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠴\u001b[0m Initializing ZenML repository at /content.\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠦\u001b[0m Initializing ZenML repository at /content.\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠧\u001b[0m Initializing ZenML repository at /content.\n",
            "\u001b[1;35mCreated and activated default profile.\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[2;36mZenML repository initialized at \u001b[0m\u001b[2;35m/\u001b[0m\u001b[2;95mcontent.\u001b[0m\n",
            "\u001b[2;32m⠧\u001b[0m\u001b[2;36m \u001b[0m\u001b[2;36mInitializing ZenML repository at /content.\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠧\u001b[0m Initializing ZenML repository at /content.\n",
            "\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36mThe local active profile was initialized to \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m and the local active stack\u001b[0m\n",
            "\u001b[2;36mto \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m. This local configuration will only take effect when you're running\u001b[0m\n",
            "\u001b[2;36mZenML from the initialized repository root, or from a subdirectory. For more \u001b[0m\n",
            "\u001b[2;36minformation on profile and stack configuration, please visit \u001b[0m\n",
            "\u001b[2;4;94mhttps://docs.zenml.io.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zenml integration install sklearn -y # code is not workig with out integrating with some libraires|"
      ],
      "metadata": {
        "id": "XDWhV1jLmkaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393d5ce0-55df-4297-b4d3-c284e93dc666"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "\u001b[2K\u001b[32m⠏\u001b[0m Installing integrations...\n",
            "\u001b[1A\u001b[2K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zenml.pipelines import pipeline\n",
        "from zenml.steps import step, Output\n"
      ],
      "metadata": {
        "id": "CiE-uYpZmwTX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5be93a5c-55aa-4909-cfd3-a2082c9d40af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zenml.materializers.base_materializer import BaseMaterializer\n",
        "from zenml.artifacts import DataArtifact"
      ],
      "metadata": {
        "id": "DYS1edrdroWc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "HLNA0TO7pRUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d534e473-ee9e-4980-f1a4-2aee46c0e8a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.26.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import torch\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer"
      ],
      "metadata": {
        "id": "jf0YeeTMpEqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "487084cf-1a77-461e-c9e1-c85c20fc3df7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/resampy/interpn.py:114: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  _resample_loop_p(x, t_out, interp_win, interp_delta, num_table, scale, y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q git+https://github.com/vasudevgupta7/gsoc-wav2vec2@main\n",
        "!sudo apt-get install -y libsndfile1-dev\n",
        "!pip3 install -q SoundFile  "
      ],
      "metadata": {
        "id": "UY4v7oeTQMyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eac7e37-3028-4fb8-eb37-007029e4795b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 153 kB 60.3 MB/s \n",
            "\u001b[?25h  Building wheel for wav2vec2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libsndfile1-dev is already the newest version (1.0.28-4ubuntu0.18.04.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from wav2vec2 import Wav2Vec2Config\n",
        "from wav2vec2 import CTCLoss\n",
        "import soundfile as sf"
      ],
      "metadata": {
        "id": "V4anr_KcQFYN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@step\n",
        "def upload_audio_file() -> Output(path= str):\n",
        "  path=\"/content/amanda_gorman.flac\"\n",
        "  return path\n"
      ],
      "metadata": {
        "id": "b0GsDW-t7b0H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def asr_transcript(audio_file: str,\n",
        "#                    model_transcribe:Wav2Vec2ForCTC,\n",
        "#                    tokenizer_transcribe:Wav2Vec2Tokenizer,\n",
        "#                    ) -> Output(transcript= str):\n",
        "\n",
        "@step\n",
        "def asr_transcript(audio_file: str) -> Output(transcript= str):\n",
        "\n",
        "      tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
        "      model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
        "      transcript = \"\"\n",
        "\n",
        "      # Stream over 20 seconds chunks\n",
        "      stream = librosa.stream(\n",
        "          audio_file, block_length=20, frame_length=16000, hop_length=16000\n",
        "      )\n",
        "\n",
        "      for speech in stream:\n",
        "          if len(speech.shape) > 1:\n",
        "              speech = speech[:, 0] + speech[:, 1]\n",
        "\n",
        "          input_values = tokenizer(speech, return_tensors=\"pt\").input_values\n",
        "          logits = model(input_values).logits\n",
        "\n",
        "          predicted_ids = torch.argmax(logits, dim=-1)\n",
        "          transcription = tokenizer.decode(predicted_ids[0])\n",
        "          transcript += transcription.lower() + \" \"\n",
        "      print(transcript)     \n",
        "          \n",
        "      return transcript"
      ],
      "metadata": {
        "id": "kmyedxfyp75j"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# asr_transcript.entrypoint(audio_file=\"/content/Wave_files_demos_Welcome (5).wav\")"
      ],
      "metadata": {
        "id": "t90n3_uf3xq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@pipeline\n",
        "def model_1(step_1,step_2):\n",
        "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
        "    path=step_1()\n",
        "    transcription=step_2(path)"
      ],
      "metadata": {
        "id": "Ksb_beu4v_80"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1(\n",
        "    step_1=upload_audio_file(),\n",
        "    step_2=asr_transcript(),\n",
        ").run(run_name=\"run_1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0A5o0Nu6bQu",
        "outputId": "a6c75063-decd-4bce-89bf-d0fd0f5f4612"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mister president doctor byden madam vice president mister mhof americans and the world when day comes we ask ourselves where can we find light in this never ending shade the loss we carry a sea we must wade we've braved the belly of the beast we've learned that quiet isn't always peace in the norms and notions of what just is isn't always just is and yet the on as ours before we knew it somehow we do it somehow we've weathered and witnessed a nation that isn't broken but simply unfinished we the successors of a country and a time were a skinny black girl descended from slaves and raised by a single mother can dream of becoming president only to find herself reciting for one and yes we are far from polished far from pestine but that doesn't mean we are striving to form a union that is perfect we are striving to forge our union with purpose to compose a country committed to all cultures colors characters and conditions of man and so we lift our gaze not to what stands between us but what stands for us we close the divide because we know to put our future first we must first put our differences aside we lay down our arms so we can reach out our arms to one another we seek harm to none and harmony for all let the globe if nothing else say this is true that even as we grieved we grew that even as we hurt we hoped that even as we tired we tried that will forever be tied together victorious not because we will never again know defeat but because we will never again so division scripture tells us to envision that everyone shall sit under ther own vine and fig tree and no one shall make them afraid if we're to live up to our own time then victory won't lie in the blade but in all the bridges we've made that is the promised glade the hill we climb if only we dare it because being american is more than a pride we inherit it's the past we step into and how we repair it we've seen a forest that would shatter ou nation rather than share it would dest our country if it meant delaying democracy and this effort very nearly succeeded but while democracy can be periodically delayed it can never be permanently defeated in this truth in this faith we trust for while we have our eyes on the future history has its eyes on us this is the era of just redemption we feared at iis deception we did not feel prepared to be the heirs of such a terrifying hour but within it we found the power to author a new chapter to offer hope and laughter to selfe so while once we asked how could we possibly prevail over catastrophe now we assert how could catastrophe possibly prevail over us we will not march back to what was but move to what shall be a country that is bruised but whole benevolent but bold fierce and free we will not be turned around or interrupted by intimidation because we know our inaction and inertia will be the inheritance of the next generation our blunders become their dance but one thing is certain if we merge mercy with might in might with right then love becomes our legacy in change our children's birthright so let us leave behind a country better the one we left with every breath from my bronze pounded chest we will raise this wounded world into a wondrous one we will rise from the gold limbed hills of the west we will rise from the wind swept northeast where our forefathers first realized revolution we will rise from the lake rimmed cities of the midwestern states we will rise from the sun baked south ubl rebuild reconcile and recover ind every known nook of our nation an every corner called our country our people diverse and beautiful will emerge battered and beautiful when day comes we step out of the shade aflame and unafraid the new bllooms as we free it for there is always light if only we're brave enough to see it if only we're brave enough to be it \n",
            "\u001b[1;35mStep \u001b[0m\u001b[33masr_transcript\u001b[1;35m has finished in 5m14s.\u001b[0m\n",
            "\u001b[1;35mPipeline run \u001b[0m\u001b[33mrun_1\u001b[1;35m has finished in 5m14s.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"@pipeline\"\n",
        "# def model_2(step_1,step_2,step_3,step_4):\n",
        "#     \"\"\"Links all the steps together in a pipeline\"\"\"\n",
        "#     path=step_1()\n",
        "#     model=step_2().with_return_materializers(MyMaterializer_model)\n",
        "#     token=step_3().with_return_materializers(MyMaterializer_token)\n",
        "#     transcription=step_4(path,model,token)\n",
        "    \n"
      ],
      "metadata": {
        "id": "wpFxu2dsgJZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class MyMaterializer_token(BaseMaterializer):\n",
        "#     ASSOCIATED_TYPES = (Wav2Vec2Tokenizer,)\n",
        "#     ASSOCIATED_ARTIFACT_TYPES = (DataArtifact,)\n",
        "#     def handle_input() -> Wav2Vec2ForCTC:\n",
        "#         \"\"\"Read from artifact store\"\"\"\n",
        "#         tokenizer_transcribe = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
        "#         return tokenizer_transcribe"
      ],
      "metadata": {
        "id": "dASjJrryjkn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class MyMaterializer_model(BaseMaterializer):\n",
        "#     ASSOCIATED_TYPES = (Wav2Vec2ForCTC,)\n",
        "#     ASSOCIATED_ARTIFACT_TYPES = (DataArtifact,)\n",
        "#     def handle_input() -> Wav2Vec2ForCTC:\n",
        "#         \"\"\"Read from artifact store\"\"\"\n",
        "#         model_transcribe = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
        "#         return model_transcribe\n"
      ],
      "metadata": {
        "id": "uqR-KBZGiZmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_2(\n",
        "#     step_1=upload_audio_file(),\n",
        "#     step_2=model_load().with_return_materializers(MyMaterializer_model),\n",
        "#     step_3=token_load().with_return_materializers(MyMaterializer_token),\n",
        "#     step_4=asr_transcript(),\n",
        "# ).run(run_name=\"run_3\")"
      ],
      "metadata": {
        "id": "i5WLww8ogpwb"
      },
      "execution_count": 56,
      "outputs": []
    }
  ]
}